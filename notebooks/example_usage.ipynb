{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VisTool Example Usage\n",
    "\n",
    "This Jupyter Notebook demonstrates how to use the `VisTool` for downloading data, combining datasets, cleaning and wrangling data and visualizing results. Each module in the `VisTool` provides specific functionalities to streamline data analysis workflows.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure the `VisTool` is installed in your environment before proceeding please see READ.ME for how to install VisTool\n",
    "\n",
    "# Download Module \n",
    "\n",
    "1. `download_file`: Downloads a file from a given URL and saves it locally.\n",
    "\n",
    "2. `download_csv`: Downloads a CSV file from a URL and loads it into a Pandas DataFrame.\n",
    "\n",
    "3. `load_csv`: Loads a CSV file into a Pandas DataFrame from local path.\n",
    "\n",
    "4. `load_excel`: Load excel file into a Pandas DataFrame from local path. \n",
    "\n",
    "5. `summarize_data`: Summarizes key aspects of the dataset and provides an overview of its structure.\n",
    "\n",
    "## Combine Module \n",
    "\n",
    "1. `merge_datasets`: Merges two datasets on a specified column.\n",
    "\n",
    "2. `concat_datasets`: Concatenates multiple datasets along rows or columns.\n",
    "\n",
    "## Visualize Module \n",
    "1. `plot_histogram`: Plots a histogram of a column.\n",
    "\n",
    "2. `plot_scatter`: Creates a scatter plot of two columns.\n",
    "\n",
    "3. `plot_correlation_matrix`: Plots a heatmap of correlations between numeric columns.\n",
    "\n",
    "4. `plot_line`: Plots a line chart for time-series data.\n",
    "\n",
    "5. `plot_overlay`: Overlays multiple columns with different plot types.\n",
    "\n",
    "## Wrangle Module \n",
    " 1. `clean_data`: Cleans the dataset by dropping NaN values or filling with mean.\n",
    "\n",
    "2. `filter_data`: Filters rows based on a condition.\n",
    "\n",
    "3. `rename_columns`: Renames columns in the dataset.\n",
    "\n",
    "4. `label_encode`: Perform label encoding on a categorical column using Pandas and NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the package information and if it is installed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should work!\n",
    "import VisTool\n",
    "print(VisTool.__version__)\n",
    "print(VisTool.__name__)\n",
    "print(VisTool.__author__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Module Example Usage \n",
    "\n",
    "1. download_file(url: str, save_path: str) -> None\n",
    "\n",
    "2. download_csv(url: str) -> pd.DataFrame\n",
    "\n",
    "3. load_csv(file_path: str) -> pd.DataFrame\n",
    "\n",
    "4. load_excel(file_path: str, sheet_name: str = None) -> pd.DataFrame\n",
    "\n",
    "5. summarize_data(df)\n",
    "\n",
    "Summarizes key aspects of the dataset and provides an overview of its structure, including:\n",
    "\n",
    "\t• Shape (rows, columns)\n",
    "\n",
    "\t• Numeric and non-numeric columns\n",
    "\n",
    "\t• Missing values\n",
    "\n",
    "\t• Duplicate rows\n",
    "\n",
    "\t• Categorical columns\n",
    "\n",
    "\t• Correlation matrix for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the download functions\n",
    "from VisTool.download import download_file,download_csv, load_csv,load_excel, summarize_data\n",
    "import os\n",
    "\n",
    "# Download a file and save it locally\n",
    "url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/airtravel.csv\"\n",
    "save_path = \"data/airtravel.csv\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Download the file\n",
    "download_file(url, save_path)\n",
    "\n",
    "# Verify the file is saved\n",
    "if os.path.exists(save_path):\n",
    "    print(f\"File downloaded successfully and saved to: {save_path}\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "#  Download a CSV file and load into Pandas DataFrame\n",
    "url = \"https://people.sc.fsu.edu/~jburkardt/data/csv/airtravel.csv\"\n",
    "df = download_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"Downloaded CSV Data:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file \n",
    "\n",
    "df = load_csv('data/Monthly_AE_Attendances_Nov_2024.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load_excel file \n",
    "df_dict = load_excel('data/titanic3.xls')\n",
    "print(type(df_dict))  # Output: <class 'dict'>\n",
    "print(df_dict.keys())  # Output: dict_keys(['Sheet1', 'Sheet2', ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dict['titanic3']  # Access the DataFrame for the 'titanic3' sheet\n",
    "print(df.head(5))  # Display the first 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary of the data \n",
    "df = load_csv('data/Monthly_AE_Attendances_Nov_2024.csv')\n",
    "summarize_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Module Example Usage\n",
    "\n",
    "The combine.py module allows for merging and concatenating datasets, making it easier to integrate and manage data. Below is a detailed explanation of the features along with examples.\n",
    "\n",
    "1.`merge_datasets(left_df, right_df, on, how)`\n",
    "\n",
    "This function merges two datasets on a specified column using various join methods (inner, outer, left, right).\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• `left_df (pd.DataFrame)`: The first dataset.\n",
    "\n",
    "• `right_df (pd.DataFrame)`: The second dataset.\n",
    "\n",
    "• `on (str)`: The column to merge on.\n",
    "\n",
    "• `how (str, optional)`: Type of join (\"inner\", \"outer\", \"left\", \"right\"). Default: \"inner\".\n",
    "\n",
    "2.`concat_datasets(dataframes, axis)`\n",
    "\n",
    "This function concatenates multiple datasets either row-wise or column-wise.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• `dataframes (list[pd.DataFrame])`: List of datasets to concatenate.\n",
    "\n",
    "• `axis (int, optional)`: Axis to concatenate on (0 for rows, 1 for columns). Default: 0.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Example 1: Inner Join\n",
    "\n",
    "from VisTool.combine import merge_datasets, concat_datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data1 = {'id': [1, 2, 3], 'name': ['Alice', 'Bob', 'Charlie']}\n",
    "data2 = {'id': [2, 3, 4], 'age': [25, 30, 35]}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge datasets inner joint \n",
    "merged_data = merge_datasets(df1, df2, on=\"id\", how=\"inner\")\n",
    "print(merged_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge datasets inner joint \n",
    "\n",
    "merged_data = merge_datasets(df1, df2, on=\"id\", how=\"outer\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating Row-Wise\n",
    "\n",
    "# Sample data\n",
    "df1 = pd.DataFrame({'id': [1, 2], 'name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'id': [3, 4], 'name': ['Charlie', 'David']})\n",
    "\n",
    "# Concatenate row-wise\n",
    "concatenated_data = concat_datasets([df1, df2], axis=0)\n",
    "print(concatenated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate column-wise\n",
    "concatenated_data = concat_datasets([df1, df2], axis=1)\n",
    "print(concatenated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Module Example Usage\n",
    "\n",
    "The wrangle module simplifies the process of preparing and managing datasets by offering both manual and interactive options for cleaning, filtering, renaming, and encoding data. The interactive functions allow users to manipulate their data directly in Jupyter Notebooks without writing additional code.\n",
    "\n",
    "`1. clean_data(data, remove_columns=None, fill_with=None, apply_to='columns')`\n",
    "\n",
    "This function cleans the dataset by dropping or filling missing values.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• data (pd.DataFrame): The input dataset.\n",
    "\n",
    "• remove_columns (list, optional): List of columns to drop rows with missing values.\n",
    "\n",
    "• fill_with (str, optional): Method to fill NaN values ('mean' or 'average').\n",
    "\n",
    "• apply_to (str, optional): Apply the operation to 'columns' or 'rows'. Default: 'columns'.\n",
    "\n",
    "\n",
    "`2. filter_data(data, condition)`\n",
    "\n",
    "Filters the dataset based on a specified condition.\n",
    "\n",
    "Arguments:\n",
    "• data (pd.DataFrame): The input dataset.\n",
    "\n",
    "• condition (str): A valid pandas query string to filter the data.\n",
    "\n",
    "\n",
    "`3. rename_columns(data, columns_mapping)`\n",
    "\n",
    "Renames columns using a dictionary mapping.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• data (pd.DataFrame): The input dataset.\n",
    "\n",
    "• columns_mapping (dict): A mapping of old column names to new names.\n",
    "\n",
    "`4. label_encode(data, column)`\n",
    "\n",
    "Applies label encoding to a categorical column.\n",
    "\n",
    "Arguments:\n",
    "• data (pd.DataFrame): The dataset containing the categorical column.\n",
    "\n",
    "• column (str): The name of the column to encode.\n",
    "\n",
    "\n",
    "\n",
    "`Interactive Variants`\n",
    "\n",
    "1. clean_data_interactive(data): Interactive version of clean_data.\n",
    "\n",
    "2. filter_data_interactive(data): Interactive version of filter_data.\n",
    "\n",
    "3. rename_columns_interactive(data): Interactive column renaming.\n",
    "\n",
    "4. label_encode_interactive(data): Interactive label encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wrangle module functions\n",
    "from VisTool.wrangle import clean_data, filter_data, rename_columns, label_encode\n",
    "import pandas as pd\n",
    "\n",
    "# a customer dataset\n",
    "data = pd.DataFrame({\n",
    "    'Customer_ID': [101, 102, 103, 104, None, 106, 107, 108],\n",
    "    'Age': [25, 30, 35, None, 40, None, 45, 50],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Annual_Income': [50000, None, 70000, 80000, 60000, 90000, None, 100000],\n",
    "    'Purchase_History': [3, 5, None, 7, 8, 9, 6, 2],\n",
    "    'City': ['NY', 'LA', 'SF', 'LA', 'NY', 'SF', 'LA', 'NY'],\n",
    "    'Customer_Type': ['Regular', 'VIP', 'Regular', 'VIP', 'Regular', 'Regular', 'VIP', 'Regular']\n",
    "})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Clean the data\n",
    "# - Remove rows where 'Customer_ID' or 'Annual_Income' is missing\n",
    "# - Fill missing values in 'Age' and 'Purchase_History' with the mean of each column\n",
    "\n",
    "cleaned_data = clean_data(data, remove_columns=['Customer_ID', 'Annual_Income'], fill_with='mean', apply_to='columns')\n",
    "\n",
    "cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Filter the data\n",
    "# - Only include customers aged over 30 who have made more than 5 purchases\n",
    "\n",
    "filtered_data = filter_data(data, \"Age > 30 and Purchase_History > 5\")\n",
    "\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 3: Rename columns\n",
    "# - Rename 'Customer_Type' to 'Customer_Category' and 'Purchase_History' to 'Purchases_Made'\n",
    "\n",
    "renamed_data = rename_columns(data, {'Customer_Type': 'Customer_Category', 'Purchase_History': 'Purchases_Made'})\n",
    "renamed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 4: Label encode the 'Gender' and 'Customer_Type' columns\n",
    "# - Convert 'Gender' (Male/Female) to 0/1 and 'Customer_Type' (Regular/VIP) to 0/1\n",
    "\n",
    "encoded_data = label_encode(data, 'Gender')\n",
    "encoded_data = label_encode(data, 'Customer_Type')\n",
    "\n",
    "# Display the final wrangled dataset\n",
    "print(\"Final Data After Wrangling:\")\n",
    "encoded_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from VisTool.wrangle import (\n",
    "    clean_data_interactive,\n",
    "    filter_data_interactive,\n",
    "    rename_columns_interactive,\n",
    "    label_encode_interactive\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Clean the dataset interactively\n",
    "\n",
    "clean_data_interactive(data)\n",
    "\n",
    "How to use:\n",
    "• Select columns to remove using the Remove Columns dropdown.\n",
    "\n",
    "• Choose “mean” or “average” to fill NaN values in numeric columns.\n",
    "\n",
    "• Specify whether to apply changes to columns or rows using the Apply To dropdown.\n",
    "\n",
    "• Click Apply Cleaning to see the updated dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clean the data\n",
    "# - Remove rows where 'Customer_ID' or 'Annual_Income' is missing\n",
    "# - Fill missing values in 'Age' and 'Purchase_History' with the mean of each column\n",
    "\n",
    "clean_data_interactive(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Filter the dataset interactively\n",
    "\n",
    "filter_data_interactive(data)\n",
    "\n",
    "How to use:\n",
    "\n",
    "• Enter a condition to filter rows in the Condition text box (e.g., Age > 30 or Gender == 'Female').\n",
    "\n",
    "• Click Apply Filter to view the filtered dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter the data\n",
    "# - Only include customers aged over 30 who have made more than 5 purchases\n",
    "# Age > 30 and Purchase_History > 5\n",
    "filter_data_interactive(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Rename columns interactively\n",
    "\n",
    "rename_columns_interactive(data)\n",
    "\n",
    "How to use:\n",
    "\n",
    "• Enter mappings for column renaming in the format old_name:new_name (e.g., Name:Full_Name,Score:Test_Score).\n",
    "\n",
    "• Click Apply Rename to see the dataset with renamed columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Rename columns\n",
    "# - Rename 'Customer_Type' to 'Customer_Category' and 'Purchase_History' to 'Purchases_Made'\n",
    "\n",
    "rename_mapping = {'Customer_Type': 'Customer_Category', \n",
    "                'Purchase_History': 'Purchase_Made'}\n",
    "\n",
    "rename_columns_interactive(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Apply label encoding interactively\n",
    "\n",
    "label_encode_interactive(data)\n",
    "\n",
    "How to use:\n",
    "\n",
    "• Select a categorical column (e.g., Gender) from the Column dropdown.\n",
    "\n",
    "• Click Apply Encoding to view the dataset with the selected column label-encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode_interactive(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Module Example Usage\n",
    "\n",
    "The visualize. module provides powerful and easy-to-use tools for creating data visualizations.  this module simplifies exploratory data analysis and presentation.\n",
    "\n",
    "\n",
    "`1. plot_histogram(data, column, bins=10, save_path=None)`\n",
    "\n",
    "Plots a histogram for a specified column to visualize its distribution.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "•\tdata (pd.DataFrame): Input dataset.\n",
    "\n",
    "•\tcolumn (str): Column to visualize.\n",
    "\n",
    "•\tbins (int, optional): Number of bins in the histogram (default: 10).\n",
    "\n",
    "•\tsave_path (str, optional): Path to save the plot (default: None).\n",
    "\n",
    "\n",
    "\n",
    "`2. plot_scatter(data, x_column, y_column, save_path=None)`\n",
    "\n",
    "Creates a scatter plot to explore the relationship between two columns.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• data (pd.DataFrame): Input dataset.\n",
    "\n",
    "• x_column (str): Column for the x-axis.\n",
    "\n",
    "• y_column (str): Column for the y-axis.\n",
    "\n",
    "• save_path (str, optional): Path to save the plot (default: None).\n",
    "\n",
    "\n",
    "\n",
    "`3. plot_correlation_matrix(data, save_path=None)`\n",
    "\n",
    "Generates a heatmap to visualize correlations between numeric columns.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• data (pd.DataFrame): Input dataset.\n",
    "\n",
    "• save_path (str, optional): Path to save the heatmap (default: None).\n",
    "\n",
    "\n",
    "`4. plot_line(data, x_column, y_column, save_path=None)`\n",
    "\n",
    "Creates a line chart, ideal for time-series or sequential data.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• data (pd.DataFrame): Input dataset.\n",
    "\n",
    "• x_column (str): Column for the x-axis (e.g., time or sequence).\n",
    "\n",
    "• y_column (str): Column for the y-axis.\n",
    "\n",
    "• save_path (str, optional): Path to save the plot (default: None).\n",
    "\n",
    "\n",
    "\n",
    "`5. plot_overlay(data, columns, plot_types, save_path=None)`\n",
    "\n",
    "Overlays multiple columns using different plot types (e.g., line, bar).\n",
    "\n",
    "Arguments:\n",
    "\n",
    "• data (pd.DataFrame): Input dataset.\n",
    "\n",
    "• columns (list): Columns to plot.\n",
    "\n",
    "• plot_types (list): List of plot types for each column ('line', 'scatter', etc.).\n",
    "\n",
    "• save_path (str, optional): Path to save the plot (default: None).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualize module functions\n",
    "import pandas as pd \n",
    "from VisTool.visualize import plot_histogram, plot_scatter, plot_correlation_matrix, plot_line, plot_overlay\n",
    "\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, 40, 45],\n",
    "    'Salary': [3000, 3500, 4000, 4500, 5000],\n",
    "    'Date': pd.date_range(start='2022-01-01', periods=5),\n",
    "    'Profit': [500, 600, 700, 800, 900]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot histogram\n",
    "plot_histogram(data, column='Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot scatter\n",
    "plot_scatter(data, x_column='Age', y_column='Salary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot correlation matrix\n",
    "plot_correlation_matrix(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot line chart\n",
    "plot_line(data, x_column='Date', y_column='Salary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Overlay plots\n",
    "plot_overlay(data, columns=['Salary', 'Profit'], plot_types=['line', 'bar'])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypi_package_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
